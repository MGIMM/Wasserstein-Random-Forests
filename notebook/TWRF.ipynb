{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "# distutils: language = c++\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "from libcpp.algorithm cimport sort,unique\n",
    "from libcpp.vector cimport vector\n",
    "from libc.math cimport ceil\n",
    "from libc.math cimport pow as pow_C \n",
    "\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel,delayed\n",
    "#import multiprocessing\n",
    "\n",
    "\n",
    "@cython.boundscheck(False) \n",
    "@cython.wraparound(False)  \n",
    "cdef inline double my_abs(double x) nogil:\n",
    "    if x > 0:\n",
    "        return x\n",
    "    else:\n",
    "        return -x\n",
    "    \n",
    "@cython.boundscheck(False) \n",
    "@cython.wraparound(False)  \n",
    "cdef inline double my_dot(double[:] x, double[:] y) nogil:\n",
    "    cdef int i\n",
    "    cdef int n = x.shape[0]\n",
    "    cdef double dot_product = 0\n",
    "    for i in range(n):\n",
    "        dot_product += x[i]*y[i]\n",
    "    return dot_product\n",
    "        \n",
    "@cython.boundscheck(False) \n",
    "@cython.wraparound(False)    \n",
    "cdef void my_unique_sorted(vector[double]& x) nogil:\n",
    "    cdef int n = x.size()\n",
    "    cdef int i\n",
    "    for i in range(n-1):\n",
    "        if x[i+1] != x[i]:\n",
    "            x.erase(x.begin()+i)\n",
    "\n",
    "# cdef vector[double] a\n",
    "# a.reserve(9)\n",
    "# cdef int i\n",
    "# for i in range(7):\n",
    "#     if i == 5:\n",
    "#         a.push_back(5)\n",
    "#     a.push_back(float(i))\n",
    "# print(a)\n",
    "# print(my_unique_sorted(a))\n",
    "  \n",
    "\n",
    "       \n",
    "# @cython.boundscheck(False) \n",
    "# @cython.wraparound(False)  \n",
    "# cdef double[:] _sort_cpp(double[:] a):\n",
    "#     # a must be c continuous (enforced with [::1])\n",
    "#     sort(&a[0], (&a[0]) + a.shape[0])\n",
    "#     return a \n",
    "\n",
    "@cython.boundscheck(False) \n",
    "@cython.wraparound(False)    \n",
    "cdef inline double _Wp(vector[double] P, vector[double] Q, int p = 2) nogil:\n",
    "    cdef int N1_int = P.size()\n",
    "    cdef int N2_int = Q.size()\n",
    "    #cdef int N1_int = P.shape[0]\n",
    "    #cdef int N2_int = Q.shape[0]\n",
    "    cdef double N1 = N1_int\n",
    "    cdef double N2 = N2_int \n",
    "    cdef vector[double] U1\n",
    "    \n",
    "    # cdef double[:] P_sorted = _sort_cpp(P)\n",
    "    # cdef double[:] Q_sorted = _sort_cpp(Q)\n",
    "    sort(P.begin(),P.end())\n",
    "    sort(Q.begin(),Q.end())\n",
    "    \n",
    "    # cdef vector[double] P_sorted\n",
    "    # P_sorted.reserve(N1_int)\n",
    "    # for j in range(N1_int):\n",
    "    #     P_sorted.push_back(P[j])\n",
    "    # \n",
    "    # cdef vector[double] Q_sorted\n",
    "    # Q_sorted.reserve(N2_int)\n",
    "    # for j in range(N2_int):\n",
    "    #     Q_sorted.push_back(Q[j])\n",
    "    # \n",
    "    # sort(P_sorted.begin(),P_sorted.end())\n",
    "    # sort(Q_sorted.begin(),Q_sorted.end())\n",
    "    \n",
    "    U1.reserve(N1_int+1)\n",
    "    cdef double _i = 1\n",
    "    U1.push_back(0)\n",
    "    cdef int j\n",
    "    cdef int i\n",
    "    for j in range(N1_int):\n",
    "        U1.push_back(_i/N1)\n",
    "        _i += 1.\n",
    "        \n",
    "    _i = 1    \n",
    "    \n",
    "    cdef vector[double] U2\n",
    "    U2.reserve(N2_int)\n",
    "    for j in range(N2_int):\n",
    "        U2.push_back(_i/N2)\n",
    "        _i += 1\n",
    "    cdef vector[double] U\n",
    "    # concatenate & remove duplicates & sort\n",
    "    U.reserve(U1.size()+U2.size())\n",
    "    U.insert( U.end(), U1.begin(), U1.end() )\n",
    "    U.insert( U.end(), U2.begin(), U2.end() )\n",
    "    sort(U.begin(),U.end())\n",
    "    #U.erase(unique(U.begin(),U.end()),U.end())\n",
    "    my_unique_sorted(U)\n",
    "    \n",
    "    \n",
    "    cdef int N_max = U.size() - 1\n",
    "    \n",
    "    #cdef double N_max_double = N_max \n",
    "    cdef double dist = 0\n",
    "    # cdef int index1\n",
    "    # cdef int index2\n",
    "    # print(U)\n",
    "    # print(P)\n",
    "    # print(Q)\n",
    "    for i in range(N_max):\n",
    "        # index1 = int(ceil(U[i]*(N1-1)))\n",
    "        # index2 = int(ceil(U[i]*(N2-1)))\n",
    "        dist += pow_C(my_abs(P[int(ceil(U[i]*(N1-1)))] - Q[int(ceil(U[i]*(N2-1)))]),p)*(U[i+1] - U[i])\n",
    "        #Wp_dist += P[int(ceil(U[i]*(N1-1)))] - Q[int(ceil(U[i]*(N2-1)))]\n",
    "        #dist += 1\n",
    "        #print(int(ceil(U[i]*(N1-1))))\n",
    "    #return pow_C(dist,1./float(p)) \n",
    "    return dist\n",
    "\n",
    "# calculate Wp difference for a subsample \n",
    "@cython.boundscheck(False) \n",
    "@cython.wraparound(False)    \n",
    "cdef inline double _calculate_Wp_difference(int[:] A,\n",
    "                                     int mtry,\n",
    "                                     double[:] split_direction,\n",
    "                                     double split_value,\n",
    "                                     double[:,:] X,\n",
    "                                     double[:] Y,\n",
    "                                     int p = 2):\n",
    "    cdef int A_size = A.shape[0]\n",
    "    cdef vector[double] Y_left\n",
    "    cdef vector[double] Y_right\n",
    "    Y_left.reserve(A_size)\n",
    "    Y_right.reserve(A_size)\n",
    "    \n",
    "    cdef int i\n",
    "    cdef int _i\n",
    "    for i in range(A_size):\n",
    "        _i = A[i]\n",
    "        if my_dot(X[_i],split_direction) < split_value:\n",
    "            Y_left.push_back(Y[_i])\n",
    "            #Y_left.push_back(1)\n",
    "        else:\n",
    "            Y_right.push_back(Y[_i])\n",
    "            #Y_right.push_back(1)\n",
    "    return _Wp(P = Y_left,Q = Y_right, p = p) \n",
    "    #return ot.wasserstein_1d(np.array(Y_left),np.array(Y_right), p = p)\n",
    "\n",
    "@cython.boundscheck(False) \n",
    "#@cython.wraparound(False)    \n",
    "def getALAR(int[:] A,\n",
    "            double[:] split_direction,\n",
    "            double split_value,\n",
    "            double[:,:] X):\n",
    "    \n",
    "    cdef vector[int] _AL\n",
    "    cdef vector[int] _AR\n",
    "    cdef int A_size = A.shape[0]\n",
    "    _AL.reserve(A_size)\n",
    "    _AR.reserve(A_size)\n",
    "    for i in range(A_size):\n",
    "        if my_dot(X[A[i]],split_direction) < split_value:\n",
    "            _AL.push_back(A[i])\n",
    "        else:\n",
    "            _AR.push_back(A[i])\n",
    "            \n",
    "    #cdef int[:] AL = _AL.data()\n",
    "    #cdef int[:] AR = _AR.data()\n",
    "    \n",
    "    # cdef int *AL = &_AL[0]    \n",
    "    # cdef int[::1] AL_view = <int[:_AL.size()]>AL    # cast to typed memory view\n",
    "    \n",
    "    # cdef int *AR = &_AL[0]    \n",
    "    # cdef int[::1] AR_view = <int[:_AL.size()]>AR\n",
    "    # # \n",
    "    return np.asarray(_AL,dtype=np.intc),np.asarray(_AR,dtype=np.intc)\n",
    "    #return 0 \n",
    "\n",
    "\n",
    "\n",
    "@cython.boundscheck(False) \n",
    "@cython.wraparound(False)    \n",
    "cdef inline double[:] getDirection(int d):\n",
    "    cdef double[:] x = np.random.normal(0,1,d)\n",
    "    cdef int i\n",
    "    cdef double NUM =0  \n",
    "    for i in range(d):\n",
    "        NUM += pow_C(x[i],2)\n",
    "    NUM = pow_C(NUM,0.5)\n",
    "    for i in range(d):\n",
    "        x[i] /= NUM\n",
    "    return x\n",
    "        \n",
    "\n",
    "# Wp_split\n",
    "@cython.boundscheck(False) \n",
    "#@cython.wraparound(False)    \n",
    "def Wp_split(int[:] A,\n",
    "             int mtry,\n",
    "             double[:,:] X,\n",
    "             double[:] Y,\n",
    "             int p = 2):\n",
    "    \n",
    "    cdef int A_size = A.shape[0]  \n",
    "    \n",
    "    cdef int _size_list = (A_size-1)*mtry\n",
    "    cdef int d = X.shape[1]\n",
    "    \n",
    "    cdef double[:,:] direction_list = np.zeros((mtry,d)) \n",
    "    #direction_list.reserve(_size_list)\n",
    "    cdef vector[int] index_direction_list\n",
    "    cdef vector[double] value_list \n",
    "    value_list.reserve(_size_list)\n",
    "    index_direction_list.reserve(_size_list)\n",
    "    \n",
    "    cdef double[:] split_direction = np.zeros(d)\n",
    "    \n",
    "    cdef vector[double] Xtry \n",
    "    Xtry.reserve(A_size)\n",
    "    \n",
    "    cdef int i\n",
    "    cdef int j\n",
    "    \n",
    "    for i in range(mtry):\n",
    "        split_direction = getDirection(d) \n",
    "        #Xtry = np.sort(list(set(X[A,:][:,split_direction])))\n",
    "        for j in range(A_size):\n",
    "            Xtry.push_back(my_dot(X[A[j]],split_direction))\n",
    "        sort(Xtry.begin(),Xtry.end())\n",
    "        #print(\"X_before\",Xtry.size())\n",
    "        Xtry.erase(unique(Xtry.begin(),Xtry.end()),Xtry.end())\n",
    "        #print(\"X_after\",Xtry.size())\n",
    "        #Xtry = np.sort(list(set(X[A,split_direction])))\n",
    "        #candidate_current_direction = (Xtry[min_sample_each_node:] + Xtry[:-min_sample_each_node])*.5\n",
    "        \n",
    "        direction_list[i] = split_direction\n",
    "        \n",
    "        for j in range(Xtry.size() - 1):\n",
    "            index_direction_list.push_back(i)\n",
    "            value_list.push_back((Xtry[j+1]+Xtry[j])*0.5)\n",
    "        Xtry.clear()\n",
    "        #theta_list += [[split_direction,candidate_current_direction[i]] for i in range(len(Xtry) -min_sample_each_node)]\n",
    "    \n",
    "    #print(\"values:\",value_list)\n",
    "    cdef vector[double] Wp_list\n",
    "    Wp_list.reserve(value_list.size())\n",
    "    for i in range(value_list.size()):\n",
    "        Wp_list.push_back(_calculate_Wp_difference(A = A,\n",
    "                                                   mtry = mtry,\n",
    "                                                   split_direction = direction_list[index_direction_list[i]],\n",
    "                                                   split_value = value_list[i],\n",
    "                                                   X = X,\n",
    "                                                   Y = Y,\n",
    "                                                   p = p))\n",
    "        \n",
    "    #cdef int argMax = max_element(Wp_list.begin(), Wp_list.end())-Wp_list.begin()\n",
    "    # cdef double *Wp_array = &Wp_list[0]    \n",
    "    # cdef double[::1] Wp_view = <double[:Wp_list.size()]>Wp_array\n",
    "    #Wp_np = np.asarray(Wp_view)\n",
    "    \n",
    "    cdef int index_max = my_argmax(Wp_list) \n",
    "# \n",
    "    return direction_list[index_direction_list[index_max]], value_list[index_max] \n",
    "\n",
    "@cython.boundscheck(False) \n",
    "#@cython.wraparound(False)    \n",
    "cdef inline int my_argmax(vector[double] x) nogil:\n",
    "    cdef int i\n",
    "    cdef int _i = 0\n",
    "    cdef double _x = x[0]\n",
    "    for i in range(x.size()):\n",
    "        if x[i] >= _x:\n",
    "            _i = i\n",
    "            _x = x[i]\n",
    "    return _i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class node:\n",
    "    def __init__(self, left = None, right = None, parent = None, direction = None,value = None, neighbours = None, nodes = None):\n",
    "        self.left = left \n",
    "        self.right = right \n",
    "        self.direction = direction  \n",
    "        self.value = value  \n",
    "        self.neighbours = neighbours \n",
    "        \n",
    "class DecisionTree:\n",
    "    def __init__(self,\n",
    "                 mtry = 1,\n",
    "                 nodesize = 5,\n",
    "                 subsample = 100,\n",
    "                 bootstrap = True,\n",
    "                 p = 2,\n",
    "                 nodes = None):\n",
    "        #self.nodes = nodes # P \n",
    "        # parameters\n",
    "        self.mtry = mtry\n",
    "        self.nodesize = nodesize\n",
    "        self.subsample = subsample \n",
    "        self.bootstrap = bootstrap \n",
    "        self.p = p \n",
    "        self.Y = None\n",
    "        self.root = None\n",
    "        self.P = None\n",
    "    def fit(self,X,Y):\n",
    "        self.Y = Y\n",
    "        N,d = X.shape \n",
    "        # if self.subsample <= 1:\n",
    "        #     subsample_size = int(N*self.subsample)\n",
    "        # elif self.subsample > 1:\n",
    "        #     subsample_size = int(self.subsample)\n",
    "        # else:\n",
    "        #     subsample_size = 100\n",
    "        #     print(\"Wrong subsample is given, used subsample = 100 as default.\")\n",
    "        S_b = np.random.choice(range(N), self.subsample, replace  = self.bootstrap)\n",
    "        self.root = node(neighbours = S_b)\n",
    "        self.P =[self.root] \n",
    "        while self.P:\n",
    "            # A is current node\n",
    "            A = self.P[0] \n",
    "            if len(A.neighbours) < self.nodesize or len(set(Y[A.neighbours])) == 1:\n",
    "                del self.P[0]\n",
    "            else:\n",
    "                #Mtry = np.random.choice(range(d),self.mtry,replace = False)\n",
    "                #print(type(np.array(Mtry,dtype = int)[0]))\n",
    "                direction,value = Wp_split(np.array(A.neighbours,dtype = np.intc),np.intc(self.mtry),X,Y,self.p)\n",
    "                A.direction = direction \n",
    "                A.value = value \n",
    "                #theta_star_list += [theta_star] \n",
    "                AL,AR = getALAR(np.array(A.neighbours,dtype = np.intc),direction,value,X)\n",
    "                del self.P[0]\n",
    "                A.left = node(neighbours = AL)\n",
    "                A.right = node(neighbours = AR)\n",
    "                self.P += [A.left,A.right]\n",
    "        \n",
    "    def _predict(self,x):\n",
    "        current_node = self.root\n",
    "        while current_node.value:\n",
    "            direction = current_node.direction\n",
    "            value = current_node.value\n",
    "            if np.dot(x,direction)<value:\n",
    "                current_node = current_node.left\n",
    "            else:\n",
    "                current_node = current_node.right\n",
    "        return np.mean(self.Y[current_node.neighbours])\n",
    "    def predict_distribution(self,x):\n",
    "        current_node = self.root\n",
    "        while current_node.value:\n",
    "            direction= current_node.direction\n",
    "            value= current_node.value\n",
    "            if np.dot(x,direction)<value:\n",
    "                current_node = current_node.left\n",
    "            else:\n",
    "                current_node = current_node.right\n",
    "        N_final = self.Y.shape[0]\n",
    "        empirical_measure = np.zeros(N_final)\n",
    "        for i in current_node.neighbours:\n",
    "            empirical_measure[i] += 1.\n",
    "        return empirical_measure/float(len(current_node.neighbours))\n",
    "            \n",
    "    def predict(self,x):\n",
    "        return np.apply_along_axis(lambda x : self._predict(x),1,x)\n",
    "        \n",
    "class WassersteinRandomForest:\n",
    "    def __init__(self,\n",
    "                 mtry = 1,\n",
    "                 nodesize = 5,\n",
    "                 subsample = 0.1,\n",
    "                 bootstrap = False,\n",
    "                 n_estimators = 10,\n",
    "                 n_jobs = 1,\n",
    "                 progressbar = True,\n",
    "                 p = 2):\n",
    "        # parameters\n",
    "        self.mtry = mtry\n",
    "        self.nodesize = nodesize\n",
    "        self.subsample = subsample \n",
    "        self.bootstrap = bootstrap \n",
    "        self.n_estimators = n_estimators\n",
    "        self.n_jobs = n_jobs\n",
    "        self.progressbar = progressbar\n",
    "        #self.n_jobs = 1 \n",
    "        self.p = p\n",
    "        #self.ListLearners = None \n",
    "        self.ListLearners = []\n",
    "        self.Y = None\n",
    "        \n",
    "    def reset_random_state(self):\n",
    "        f = open(\"/dev/random\",\"rb\")\n",
    "        rnd_str = f.read(4)\n",
    "        rnd_int = int.from_bytes(rnd_str, byteorder = 'big')\n",
    "        np.random.seed(rnd_int)\n",
    "\n",
    "    def _fit(self,X,Y):\n",
    "        if self.n_jobs > 1:\n",
    "            self.reset_random_state()\n",
    "        BaseLearner = DecisionTree(mtry = self.mtry,\n",
    "                                   nodesize = self.nodesize,\n",
    "                                   subsample = self.subsample,\n",
    "                                   bootstrap = self.bootstrap,\n",
    "                                   p = self.p)\n",
    "        BaseLearner.fit(X,Y)\n",
    "        return BaseLearner\n",
    "\n",
    "    def fit(self,X,Y):\n",
    "        self.Y = Y\n",
    "        if self.n_jobs ==1:\n",
    "            #self.ListLearners = []\n",
    "            if self.progressbar:\n",
    "                fit_tqdm = tqdm(range(self.n_estimators)) \n",
    "                for i in fit_tqdm:\n",
    "                    self.ListLearners += [self._fit(X,Y)]\n",
    "            else:\n",
    "                for i in range(self.n_estimators):\n",
    "                    self.ListLearners += [self._fit(X,Y)]\n",
    "        else:\n",
    "            ListLearners = Parallel(n_jobs=self.n_jobs)(delayed(self._fit)(X,Y) for i in tqdm(range(self.n_estimators)))\n",
    "\n",
    "            #results =\\\n",
    "            #Parallel(n_jobs=self.n_jobs)(delayed(self._fit) (X=X,Y=Y) for i in tqdm(range(self.n_estimators)))\n",
    "        #fit_tqdm.reset()\n",
    "            #self.ListLearners = results \n",
    "    # def fit(self,X,Y):\n",
    "    #     self.Y = Y\n",
    "    #     for i in tqdm(range(self.n_estimators)):\n",
    "    #         #BaseLearner = DecisionTree(mtry = self.mtry,\n",
    "    #         #                           nodesize = self.nodesize,\n",
    "    #         #                           subsample = self.subsample,\n",
    "    #         #                           bootstrap = self.bootstrap,\n",
    "    #         #                           p = self.p)\n",
    "    #         #BaseLearner.fit(X,Y)\n",
    "    #         self.ListLearners += [self._fit(X,Y)]\n",
    "    def predict(self,x):\n",
    "        prediction = np.zeros(x.shape[0])\n",
    "        for i in range(self.n_estimators):\n",
    "            prediction += self.ListLearners[i].predict(x)\n",
    "        prediction /= float(self.n_estimators)\n",
    "        return prediction\n",
    "    def predict_distribution(self,x):\n",
    "        empirical_measure = np.zeros(len(self.Y))\n",
    "        for i in range(self.n_estimators):\n",
    "            current_empirical_measure= self.ListLearners[i].predict_distribution(x)\n",
    "            empirical_measure += current_empirical_measure\n",
    "        return self.Y,empirical_measure/float(self.n_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating synthetic dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "N_total =55000\n",
    "N_train =50000\n",
    "X = np.random.uniform(0,1,(N_total,5))\n",
    "#X = np.random.normal(0,1,(N_total,10))\n",
    "def obj_func(x):\n",
    "    \"\"\"\n",
    "    conditional expectation\n",
    "    \"\"\"\n",
    "    # x0_tilde = 2.*(x[0] - 0.5)\n",
    "    # x1_tilde = 2.*(x[1] - 0.5)\n",
    "    # return x0_tilde**2 + x[3]*x[4]\n",
    "    # c = 0\n",
    "    # for i in range(3):\n",
    "    #     #c *= x[i]*np.sin(i)\n",
    "    #     c += x[i]*np.sin(i)\n",
    "    return 10*x[1] + x[2]\n",
    "def obj_func2(x):\n",
    "    \"\"\"\n",
    "    conditional variance\n",
    "    \"\"\"\n",
    "    #return np.abs(np.sin(x[0])+x[1])*1.5\n",
    "    #return np.abs(x[0]+x[1])*1.5\n",
    "    return np.max([x[3]*9., 0.2])\n",
    "    #return 0.5\n",
    "\n",
    "# def obj_func3(x):\n",
    "#     \"\"\"\n",
    "#     conditional expectation\n",
    "#     \"\"\"\n",
    "#     #return x[1]+2.*x[2] +2. +np.sin(2.*x[0])\n",
    "#     c = 0\n",
    "#     for i in range(4,7):\n",
    "#         #c *= x[i]*np.sin(i)\n",
    "#         c += x[i]*np.cos(i)\n",
    "#     #return x[1] + x[2]\n",
    "#     return c\n",
    "\n",
    "\n",
    "#Y = np.random.normal(0,1.,N_total) + np.apply_along_axis(obj_func,1,X)\n",
    "Y = np.zeros(N_total)\n",
    "for i in range(N_total):\n",
    "    if np.random.rand()<0.5:\n",
    "        Y[i] = np.random.normal(obj_func(X[i]),np.sqrt(obj_func2(X[i])),1)\n",
    "    else:\n",
    "        #Y[i] = np.random.normal(obj_func(X[i]),np.sqrt(obj_func2(X[i])),1)\n",
    "        # Y[i] = np.random.normal(-0.05*obj_func2(X[i]),1,1)\n",
    "        #Y[i] = np.random.normal(-1.5*obj_func2(X[i]),1,1)\n",
    "        #Y[i] = np.random.normal(obj_func3(X[i]),1,1)\n",
    "\n",
    "        #Y[i] = np.random.normal(-1,1,1)\n",
    "        Y[i] = np.random.normal(obj_func(X[i]),np.sqrt(obj_func2(X[i])),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_total = 7000 \n",
    "N_train = 5000 \n",
    "X = np.random.uniform(0,1,(N_total,50))\n",
    "#X = np.random.normal(0,1,(N_total,10))\n",
    "def obj_func(x):\n",
    "    \"\"\"\n",
    "    conditional expectation\n",
    "    \"\"\"\n",
    "    # x0_tilde = 2.*(x[0] - 0.5)\n",
    "    # x1_tilde = 2.*(x[1] - 0.5)\n",
    "    # return x0_tilde**2 + x[3]*x[4] \n",
    "    # c = 0\n",
    "    # for i in range(3):\n",
    "    #     #c *= x[i]*np.sin(i)\n",
    "    #     c += x[i]*np.sin(i)\n",
    "    #return 10.*x[1] + x[2]\n",
    "    return 10.*x[1]*x[3]**2 + x[2] + np.exp(x[3]-2*x[0]+np.sin(x[1]**3))\n",
    "def obj_func2(x):\n",
    "    \"\"\"\n",
    "    conditional variance\n",
    "    \"\"\"\n",
    "    #return np.abs(np.sin(x[0])+x[1])*1.5 \n",
    "    #return np.abs(x[0]+x[1])*1.5 \n",
    "    #return np.max([(x[0]+x[1])*2.5, 0.2])\n",
    "    return np.max([(x[0]*x[1]+np.cos(x[2]*x[3]**2))*2.5, 0.2])\n",
    "    #return 0.5 \n",
    "    \n",
    "def obj_func3(x):\n",
    "    \"\"\"\n",
    "    conditional expectation\n",
    "    \"\"\"\n",
    "    #return x[1]+2.*x[2] +2. +np.sin(2.*x[0])\n",
    "    c = 0\n",
    "    for i in range(4,7):\n",
    "        #c *= x[i]*np.sin(i)\n",
    "        c += x[i]*np.cos(i)\n",
    "    #return x[1] + x[2]\n",
    "    return c\n",
    "\n",
    "\n",
    "#Y = np.random.normal(0,1.,N_total) + np.apply_along_axis(obj_func,1,X)\n",
    "Y = np.zeros(N_total)\n",
    "for i in range(N_total):\n",
    "    if np.random.rand()<0.5:\n",
    "        Y[i] = np.random.normal(obj_func(X[i]),np.sqrt(obj_func2(X[i])),1) \n",
    "    else:\n",
    "        #Y[i] = np.random.normal(obj_func(X[i]),np.sqrt(obj_func2(X[i])),1) \n",
    "        # Y[i] = np.random.normal(-0.05*obj_func2(X[i]),1,1) \n",
    "        #Y[i] = np.random.normal(-1.5*obj_func2(X[i]),1,1) \n",
    "        #Y[i] = np.random.normal(obj_func3(X[i]),1,1) \n",
    "        \n",
    "        Y[i] = np.random.normal(-1,1,1) \n",
    "        #Y[i] = np.random.normal(obj_func(X[i]),np.sqrt(obj_func2(X[i])),1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 1/200 [00:05<18:31,  5.59s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 2/200 [00:11<18:53,  5.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 3/200 [00:17<18:42,  5.70s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c7052eb4971a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                              p = 2)\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#reg = DecisionTree()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mN_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mN_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-a642ed0f6c93>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mfit_tqdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfit_tqdm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListLearners\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-a642ed0f6c93>\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    122\u001b[0m                                    \u001b[0mbootstrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbootstrap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                                    p = self.p)\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mBaseLearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mBaseLearner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-a642ed0f6c93>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;31m#Mtry = np.random.choice(range(d),self.mtry,replace = False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;31m#print(type(np.array(Mtry,dtype = int)[0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWp_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbours\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmtry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reg = WassersteinRandomForest(nodesize = 2,\n",
    "                             bootstrap = False,\n",
    "                             subsample = 500,\n",
    "                             n_estimators = 200,\n",
    "                             mtry = 1,\n",
    "                             n_jobs = 1,\n",
    "                             p = 2)\n",
    "#reg = DecisionTree()\n",
    "reg.fit(X[:N_train],Y[:N_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional expectation estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "predlist = reg.predict(X[N_train:])\n",
    "print(\"Wasserstein RF\")\n",
    "print(\"R2:\",r2_score(np.apply_along_axis(obj_func,1,X[N_train:]),predlist))\n",
    "print(\"MSE:\",\n",
    "        np.sqrt(mean_squared_error(np.apply_along_axis(obj_func,1,X[N_train:]),predlist))\n",
    "     )\n",
    "#print(\"Memory usage:\", process.memory_info().rss/1024/1024,\"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with classical Random Forests\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from skgarden import MondrianForestRegressor\n",
    "\n",
    "reg2 = RandomForestRegressor(n_estimators = 100,\n",
    "                             min_samples_split = 2,\n",
    "                             bootstrap = 1,\n",
    "                             max_features = 1 \n",
    "                            )\n",
    "# reg2 = MondrianForestRegressor(n_estimators = 500,\n",
    "#                             min_samples_split = 5,\n",
    "#                             bootstrap = False)\n",
    "reg2.fit(X[:N_train],Y[:N_train])\n",
    "\n",
    "print(\"Classical RF\")\n",
    "print(\"R2:\",r2_score(np.apply_along_axis(obj_func,1,X[N_train:]),reg2.predict(X[N_train:])))\n",
    "print(\"MSE:\",\n",
    "        np.sqrt(mean_squared_error(np.apply_along_axis(obj_func,1,X[N_train:]),reg2.predict(X[N_train:])))\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional distribution estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import kdeplot\n",
    "\n",
    "plt.figure(figsize = (20,15))\n",
    "for IndexPlot in range(9):\n",
    "    plt.subplot(int(\"33\"+str(IndexPlot+1)))\n",
    "    TestIndex = np.random.choice(range(N_total-N_train),1)[0]\n",
    "    #TestIndex = np.random.choice(range(N_train),1)[0]\n",
    "    #plt.hist(Y, density = True, color = \"orange\",alpha = 0.3, bins = 20, label=\"Y\")\n",
    "    kdeplot(Y, label=\"kde-Y\", color = \"darkorange\")\n",
    "    Y,W = reg.predict_distribution(X[-TestIndex])\n",
    "    kdeplot(np.random.choice(a = Y,p = W,size = 1000), label=\"kde-pred\", color = \"black\")\n",
    "    plt.hist(Y,weights=W, bins = 20, color = \"grey\", density = True,alpha = 0.5, label=\"pred\")\n",
    "    #ref_sample = np.random.normal(obj_func(X[-TestIndex]),np.sqrt(obj_func2(X[-TestIndex])),2000)\n",
    "    ref_sample = np.zeros(2000)\n",
    "    for i in range(2000):\n",
    "        if np.random.rand()<0.5:\n",
    "            ref_sample[i] = np.random.normal(obj_func(X[-TestIndex]),np.sqrt(obj_func2(X[-TestIndex])),1)\n",
    "        else:\n",
    "            #ref_sample[i] = np.random.normal(-1.5*obj_func2(X[TestIndex]),1,1)\n",
    "            # ref_sample[i] = np.random.normal(obj_func3(X[TestIndex]),1,1)\n",
    "\n",
    "            ref_sample[i] = np.random.normal(-1,1,1)\n",
    "            #ref_sample[i] = np.random.normal(obj_func(X[-TestIndex]),np.sqrt(obj_func2(X[-TestIndex])),1)\n",
    "\n",
    "    plt.hist(ref_sample,\n",
    "             density = True, color = \"darkred\",alpha = 0.3, bins = 20, label=\"ref\")\n",
    "    kdeplot(ref_sample, label = \"kde-ref\", color = \"darkred\")\n",
    "    plt.grid(linestyle = \"-.\",color=\"lightgrey\")\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Calculate average Wp distance with 100 points in test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ot import wasserstein_1d\n",
    "predlist = []\n",
    "predlistY = []\n",
    "ideallist = []\n",
    "for i in range(100):\n",
    "    Y_c,W_c = reg.predict_distribution(X[N_train+i])\n",
    "    predlist +=[wasserstein_1d(p = 2,x_a = np.random.choice(Y_c,p=W_c,size = 100000),x_b =np.random.normal(obj_func(X[N_train+i]),np.sqrt(obj_func2(X[N_train+i])),100000))]\n",
    "    #predlist +=[wasserstein_1d(p = 2,x_a = Y_c,a = W_c,x_b =np.random.normal(obj_func(X[N_train+i]),np.sqrt(obj_func2(X[N_train+i])),100000))]\n",
    "    predlistY +=[wasserstein_1d(p = 2,x_a = Y[:N_train],x_b =np.random.normal(obj_func(X[N_train+i]),np.sqrt(obj_func2(X[N_train+i])),100000))]\n",
    "    #ideallist += [wasserstein_1d(p = 2,x_a =np.random.normal(obj_func(X[N_train+i]),np.sqrt(obj_func2(X[N_train+i])),N_train),\n",
    "                                   #x_b = np.random.normal(obj_func(X[N_train+i]),np.sqrt(obj_func2(X[N_train+i])),10000))] \n",
    "print(\"average Wp distance:\", np.mean(predlist))\n",
    "print(\"average Wp distance with Y (i.e., no estimation is made):\", np.mean(predlistY))\n",
    "#print(\"ideal average Wp distance\", np.mean(ideallist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ot import wasserstein_1d\n",
    "predlist = []\n",
    "predlistY = []\n",
    "ideallist = []\n",
    "for i in range(100):\n",
    "    TestIndex = np.random.choice(range(N_total-N_train),1)[0]\n",
    "    Y_c,W_c = reg.predict_distribution(X[-TestIndex])\n",
    "    x_b_test = np.zeros(10000)\n",
    "    for i in range(10000):\n",
    "        if np.random.rand()<0.5:\n",
    "            x_b_test[i] = np.random.normal(obj_func(X[-TestIndex]),np.sqrt(obj_func2(X[-TestIndex])),1)[0]\n",
    "        else:\n",
    "            x_b_test[i] = np.random.normal(-1,1,1)[0]\n",
    "    predlist +=[wasserstein_1d(p = 2,x_a = np.random.choice(Y_c,p=W_c,size = 10000),x_b =x_b_test)]\n",
    "print(\"average Wp distance:\", np.mean(predlist))\n",
    "#print(\"average Wp distance with Y (i.e., no estimation is made):\", np.mean(predlistY))\n",
    "#print(\"ideal average Wp distance\", np.mean(ideallist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "list_dist_rf = []\n",
    "for j in tqdm(range(100)):\n",
    "    TestIndex = np.random.choice(range(N_total-N_train),1)[0]\n",
    "    listY = []\n",
    "    for i in range(100):\n",
    "        reg2 = RandomForestRegressor(n_estimators = 1,\n",
    "                                     min_samples_split = 2,\n",
    "                                     bootstrap = False,\n",
    "                                     #max_samples = 200,\n",
    "                                     max_features = 1 \n",
    "                                    )\n",
    "        # reg2 = MondrianForestRegressor(n_estimators = 500,\n",
    "        #                             min_samples_split = 5,\n",
    "        #                             bootstrap = False)\n",
    "        reg2.fit(X[:N_train],Y[:N_train])\n",
    "        listY += [reg2.predict(X[-TestIndex].reshape(1,X[-TestIndex].shape[0]))[0]]\n",
    "    listY = np.array(listY)\n",
    "    x_b_test = np.zeros(10000)\n",
    "    for i in range(10000):\n",
    "        if np.random.rand()<0.5:\n",
    "            x_b_test[i] = np.random.normal(obj_func(X[-TestIndex]),np.sqrt(obj_func2(X[-TestIndex])),1)[0]\n",
    "        else:\n",
    "            x_b_test[i] = np.random.normal(-1,1,1)[0]\n",
    "    list_dist_rf +=[wasserstein_1d(p = 2,x_a = listY,x_b = x_b_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(list_dist_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,6))\n",
    "ref_sample = np.zeros(2000)\n",
    "for i in range(2000):\n",
    "    if np.random.rand()<0.5:\n",
    "        ref_sample[i] = np.random.normal(obj_func(X[-TestIndex]),np.sqrt(obj_func2(X[-TestIndex])),1)\n",
    "    else:\n",
    "        #ref_sample[i] = np.random.normal(-1.5*obj_func2(X[TestIndex]),1,1)\n",
    "        # ref_sample[i] = np.random.normal(obj_func3(X[TestIndex]),1,1)\n",
    "\n",
    "        ref_sample[i] = np.random.normal(-1,1,1)\n",
    "        #ref_sample[i] = np.random.normal(obj_func(X[-TestIndex]),np.sqrt(obj_func2(X[-TestIndex])),1)\n",
    "\n",
    "kdeplot(listY, label=\"kde-rf\")\n",
    "Y_c,W_c = reg.predict_distribution(X[-TestIndex])\n",
    "Y,W = reg.predict_distribution(X[-TestIndex])\n",
    "#kdeplot(np.random.choice(a = Y,p = W,size = 1000), label=\"kde-pred\", color = \"black\")\n",
    "plt.subplot(121)\n",
    "plt.hist(listY,bins = 30,density = True, label = \"rf-pred\")\n",
    "plt.hist(ref_sample,density = True, color = \"darkred\",alpha = 0.3, bins = 30, label=\"ref\")\n",
    "#kdeplot(ref_sample, label = \"kde-ref\", color = \"darkred\")\n",
    "plt.grid(linestyle=\"dotted\")\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "plt.hist(Y,weights=W, bins = 30, color = \"grey\", density = True,alpha = 1, label=\"pred\")\n",
    "plt.hist(ref_sample,density = True, color = \"darkred\",alpha = 0.3, bins = 30, label=\"ref\")\n",
    "plt.grid(linestyle=\"dotted\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
